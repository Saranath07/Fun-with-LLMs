{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting textstat\n",
      "  Using cached textstat-0.7.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyphen in /home/saranathp/.local/lib/python3.12/site-packages (from textstat) (0.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.12/site-packages (from textstat) (69.0.3)\n",
      "Using cached textstat-0.7.4-py3-none-any.whl (105 kB)\n",
      "Installing collected packages: textstat\n",
      "Successfully installed textstat-0.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DSPY_Proposal.md\", \"r\") as f:\n",
    "    ai_proposal = f.read()\n",
    "\n",
    "with open(\"human_proposal.md\", \"r\") as f:\n",
    "    human_proposal = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch-Kincaid Grade Level: 17.0\n",
      "Gunning Fog Index: 15.25\n"
     ]
    }
   ],
   "source": [
    "fk_grade = textstat.flesch_kincaid_grade(ai_proposal)\n",
    "print(f\"Flesch-Kincaid Grade Level: {fk_grade}\")\n",
    "\n",
    "# Calculate Gunning Fog Index\n",
    "gunning_fog = textstat.gunning_fog(ai_proposal)\n",
    "print(f\"Gunning Fog Index: {gunning_fog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch-Kincaid Grade Level: 13.1\n",
      "Gunning Fog Index: 10.85\n"
     ]
    }
   ],
   "source": [
    "fk_grade = textstat.flesch_kincaid_grade(human_proposal)\n",
    "print(f\"Flesch-Kincaid Grade Level: {fk_grade}\")\n",
    "\n",
    "# Calculate Gunning Fog Index\n",
    "gunning_fog = textstat.gunning_fog(human_proposal)\n",
    "print(f\"Gunning Fog Index: {gunning_fog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.29\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Reference proposal (list of tokens)\n",
    "reference = [word_tokenize(human_proposal)]\n",
    "\n",
    "# Generated proposal (list of tokens)\n",
    "candidate = word_tokenize(ai_proposal)\n",
    "\n",
    "# Compute BLEU score\n",
    "smoothie = SmoothingFunction().method4  # Smoothing to avoid zero scores\n",
    "bleu_score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Reference and candidate texts\n",
    "\n",
    "\n",
    "# Initialize scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "# Compute ROUGE-L score\n",
    "scores = scorer.score(human_proposal, ai_proposal)\n",
    "rouge_l_f1 = scores['rougeL'].fmeasure\n",
    "\n",
    "print(f\"ROUGE-L Score: {rouge_l_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch Reading Ease: 25.12\n"
     ]
    }
   ],
   "source": [
    "import textstat\n",
    "\n",
    "\n",
    "\n",
    "# Calculate Flesch Reading Ease\n",
    "flesch_score = textstat.flesch_reading_ease(ai_proposal)\n",
    "print(f\"Flesch Reading Ease: {flesch_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LanguageTool 6.4: 100%|██████████| 246M/246M [01:11<00:00, 3.44MB/s] \n",
      "INFO:language_tool_python.download_lt:Unzipping /tmp/tmp1ksz31bu.zip to /home/saranathp/.cache/language_tool_python.\n",
      "INFO:language_tool_python.download_lt:Downloaded https://www.languagetool.org/download/LanguageTool-6.4.zip to /home/saranathp/.cache/language_tool_python.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency Score (%): 100.00%\n"
     ]
    }
   ],
   "source": [
    "import language_tool_python\n",
    "\n",
    "# Initialize tool\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "\n",
    "\n",
    "# Check for errors\n",
    "matches = tool.check(ai_proposal)\n",
    "\n",
    "# Analyze matches for consistency issues\n",
    "# For demonstration, we'll assume each match is an inconsistency\n",
    "inconsistency_count = len(matches)\n",
    "total_checks = 10  # Assume total criteria is 10\n",
    "\n",
    "consistency_score = ((total_checks - inconsistency_count) / total_checks) * 100\n",
    "print(f\"Consistency Score (%): {consistency_score:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting dspy\n",
      "  Using cached dspy-2.5.6-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: backoff in /home/saranathp/.local/lib/python3.12/site-packages (from dspy) (2.2.1)\n",
      "Requirement already satisfied: datasets in /home/saranathp/.local/lib/python3.12/site-packages (from dspy) (2.21.0)\n",
      "Requirement already satisfied: joblib~=1.3 in /home/saranathp/.local/lib/python3.12/site-packages (from dspy) (1.4.2)\n",
      "Collecting litellm (from dspy)\n",
      "  Using cached litellm-1.49.0-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting openai (from dspy)\n",
      "  Using cached openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: optuna in /home/saranathp/.local/lib/python3.12/site-packages (from dspy) (4.0.0)\n",
      "Requirement already satisfied: pandas in /usr/lib64/python3.12/site-packages (from dspy) (2.2.1)\n",
      "Requirement already satisfied: pydantic~=2.0 in /home/saranathp/.local/lib/python3.12/site-packages (from dspy) (2.8.2)\n",
      "Requirement already satisfied: regex in /usr/lib64/python3.12/site-packages (from dspy) (2024.4.28)\n",
      "Requirement already satisfied: requests in /home/saranathp/.local/lib/python3.12/site-packages (from dspy) (2.32.3)\n",
      "Requirement already satisfied: structlog in /home/saranathp/.local/lib/python3.12/site-packages (from dspy) (24.4.0)\n",
      "Requirement already satisfied: tqdm in /home/saranathp/.local/lib/python3.12/site-packages (from dspy) (4.66.5)\n",
      "Requirement already satisfied: ujson in /home/saranathp/.local/lib/python3.12/site-packages (from dspy) (5.10.0)\n",
      "Requirement already satisfied: httpx in /home/saranathp/.local/lib/python3.12/site-packages (from dspy) (0.27.0)\n",
      "Requirement already satisfied: magicattr~=0.1.6 in /home/saranathp/.local/lib/python3.12/site-packages (from dspy) (0.1.6)\n",
      "Requirement already satisfied: diskcache in /home/saranathp/.local/lib/python3.12/site-packages (from dspy) (5.6.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/saranathp/.local/lib/python3.12/site-packages (from pydantic~=2.0->dspy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/saranathp/.local/lib/python3.12/site-packages (from pydantic~=2.0->dspy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/lib/python3.12/site-packages (from pydantic~=2.0->dspy) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/saranathp/.local/lib/python3.12/site-packages (from datasets->dspy) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib64/python3.12/site-packages (from datasets->dspy) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/lib64/python3.12/site-packages (from datasets->dspy) (15.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/saranathp/.local/lib/python3.12/site-packages (from datasets->dspy) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /home/saranathp/.local/lib/python3.12/site-packages (from datasets->dspy) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/saranathp/.local/lib/python3.12/site-packages (from datasets->dspy) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->dspy) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/lib64/python3.12/site-packages (from datasets->dspy) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/saranathp/.local/lib/python3.12/site-packages (from datasets->dspy) (0.24.5)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.12/site-packages (from datasets->dspy) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib64/python3.12/site-packages (from datasets->dspy) (6.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.12/site-packages (from requests->dspy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.12/site-packages (from requests->dspy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/saranathp/.local/lib/python3.12/site-packages (from requests->dspy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/saranathp/.local/lib/python3.12/site-packages (from requests->dspy) (2024.8.30)\n",
      "Requirement already satisfied: anyio in /usr/lib/python3.12/site-packages (from httpx->dspy) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/lib/python3.12/site-packages (from httpx->dspy) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /usr/lib/python3.12/site-packages (from httpx->dspy) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/lib/python3.12/site-packages (from httpcore==1.*->httpx->dspy) (0.14.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3.12/site-packages (from litellm->dspy) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /home/saranathp/.local/lib/python3.12/site-packages (from litellm->dspy) (8.0.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/lib/python3.12/site-packages (from litellm->dspy) (3.1.4)\n",
      "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm->dspy)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /home/saranathp/.local/lib/python3.12/site-packages (from litellm->dspy) (1.0.1)\n",
      "Collecting tiktoken>=0.7.0 (from litellm->dspy)\n",
      "  Using cached tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tokenizers in /home/saranathp/.local/lib/python3.12/site-packages (from litellm->dspy) (0.19.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3.12/site-packages (from openai->dspy) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/saranathp/.local/lib/python3.12/site-packages (from openai->dspy) (0.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/saranathp/.local/lib/python3.12/site-packages (from optuna->dspy) (1.13.2)\n",
      "Requirement already satisfied: colorlog in /home/saranathp/.local/lib/python3.12/site-packages (from optuna->dspy) (6.8.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/saranathp/.local/lib/python3.12/site-packages (from optuna->dspy) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3.12/site-packages (from pandas->dspy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3.12/site-packages (from pandas->dspy) (2024.2)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3.12/site-packages (from alembic>=1.5.0->optuna->dspy) (1.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/lib/python3.12/site-packages (from aiohttp->datasets->dspy) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3.12/site-packages (from aiohttp->datasets->dspy) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/lib64/python3.12/site-packages (from aiohttp->datasets->dspy) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/lib64/python3.12/site-packages (from aiohttp->datasets->dspy) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/lib64/python3.12/site-packages (from aiohttp->datasets->dspy) (1.9.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/saranathp/.local/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm->dspy) (3.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/saranathp/.local/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm->dspy) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->dspy) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->dspy) (0.31.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/lib64/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->dspy) (0.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/saranathp/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->dspy) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib64/python3.12/site-packages (from sqlalchemy>=1.3.0->optuna->dspy) (3.0.3)\n",
      "Using cached dspy-2.5.6-py3-none-any.whl (304 kB)\n",
      "Using cached litellm-1.49.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached openai-1.51.2-py3-none-any.whl (383 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Installing collected packages: tiktoken, openai, jsonschema, litellm, dspy\n",
      "Successfully installed dspy-2.5.6 jsonschema-4.23.0 litellm-1.49.0 openai-1.51.2 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:03<00:00,  9.02s/it]\n",
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated. ***\n",
      " \t\tYou are using the client Together, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**I. Introduction**\n",
      "\n",
      "The client seeks to develop an AI-driven predictive analytics system for a healthcare network, aiming to predict patient outcomes, monitor chronic diseases, and optimize hospital resource management. The system must integrate with the existing Electronic Health Record (EHR) system and provide actionable insights for medical practitioners.\n",
      "\n",
      "**II. Technical Requirements**\n",
      "\n",
      "1. **Machine Learning Models**: The client requires the use of classification models such as decision trees, logistic regression, random forests, and neural networks. The models should be trained using historical patient data and have explainable AI (XAI) features to help medical professionals understand how decisions are made.\n",
      "2. **Data Integration**: The system should integrate with the existing EHR software through APIs and handle large datasets from various healthcare sources, including EHRs, lab results, and wearable devices.\n",
      "3. **Cloud-Based Infrastructure**: The system should be deployed on a cloud-based infrastructure for real-time data processing and storage, ensuring scalability to handle increasing data loads from multiple healthcare centers.\n",
      "4. **Data Security**: The system must ensure end-to-end encryption of patient data and adherence to data privacy laws such as HIPAA.\n",
      "\n",
      "**III. System Architecture**\n",
      "\n",
      "The proposed system architecture consists of the following components:\n",
      "\n",
      "1. **Data Ingestion Layer**: Responsible for collecting and processing data from various healthcare sources.\n",
      "2. **Data Storage Layer**: Stores the processed data in a cloud-based storage system.\n",
      "3. **Machine Learning Layer**: Trains and deploys machine learning models using the stored data.\n",
      "4. **API Layer**: Provides APIs for integrating with the existing EHR system and other healthcare applications.\n",
      "5. **User Interface Layer**: Offers a user-friendly dashboard for healthcare professionals to view predictions, trends, and insights.\n",
      "\n",
      "**IV. Model Development and Training**\n",
      "\n",
      "The machine learning models will be developed and trained using the following steps:\n",
      "\n",
      "1. **Data Preprocessing**: Clean and preprocess the historical patient data.\n",
      "2. **Feature Engineering**: Extract relevant features from the preprocessed data.\n",
      "3. **Model Selection**: Select the most suitable machine learning algorithm based on the problem requirements.\n",
      "4. **Model Training**: Train the selected model using the preprocessed data.\n",
      "5. **Model Evaluation**: Evaluate the performance of the trained model using metrics such as accuracy, precision, and recall.\n",
      "\n",
      "**V. System Integration and Deployment**\n",
      "\n",
      "The system will be integrated with the existing EHR system through APIs and deployed on a cloud-based infrastructure. The following steps will be taken:\n",
      "\n",
      "1. **API Development**: Develop APIs for integrating with the existing EHR system.\n",
      "2. **System Deployment**: Deploy the system on a cloud-based infrastructure.\n",
      "3. **System Testing**: Perform thorough testing of the system to ensure its functionality and performance.\n",
      "\n",
      "**VI. Security and Compliance**\n",
      "\n",
      "The system will ensure end-to-end encryption of patient data and adherence to data privacy laws such as HIPAA. The following measures will be taken:\n",
      "\n",
      "1. **Data Encryption**: Encrypt patient data using secure encryption algorithms.\n",
      "2. **Access Control**: Implement role-based access controls to limit user permissions and data exposure.\n",
      "3. **Auditing**: Log all access to patient data for auditing purposes.\n",
      "\n",
      "**VII. Conclusion**\n",
      "\n",
      "The proposed AI-powered predictive analytics system for healthcare will provide actionable insights for medical practitioners, predict patient outcomes, and optimize hospital resource management. The system will be developed and deployed using a cloud-based infrastructure, ensuring scalability and security. The proposed system architecture, model development and training, system integration and deployment, and security and compliance measures will ensure the successful execution of the project.\n",
      "\n",
      "**VIII. Budget and Timeline**\n",
      "\n",
      "The total project budget is capped at $1.2 million, inclusive of data collection, AI model development, system integration, and security features. The project timeline is 12 months, with the following milestones:\n",
      "\n",
      "* Data Collection and Preparation: 3 months\n",
      "* Model Development and Training: 4 months\n",
      "* System Integration and API Development: 2 months\n",
      "* Testing and Validation: 2 months\n",
      "* Deployment and Staff Training: 1 month\n",
      "\n",
      "**IX. Post-Completion Support**\n",
      "\n",
      "The client requests a 12-month post-launch support period to address any technical issues or model updates. Regular model performance reviews and updates based on new data will be provided, along with ongoing training for new staff members or system changes.\n",
      "\n",
      "$ $\n",
      "\n",
      "$ \\text{Accuracy} = \\frac{\\text{True Positives} + \\text{True Negatives}}{\\text{Total Samples}} $ \n",
      "\n",
      "$ \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}} $ \n",
      "\n",
      "$ \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}} $ \n",
      "\n",
      "$ \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $ \n",
      "\n",
      "$ \\text{Mean Squared Error (MSE)} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $ \n",
      "\n",
      "$ \\text{Mean Absolute Error (MAE)} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| $ \n",
      "\n",
      "$ \\text{Root Mean Squared Error (RMSE)} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} $ \n",
      "\n",
      "$ \\text{Coefficient of Determination (R-Squared)} = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2} $ \n",
      "\n",
      "$ \\text{Information Gain} = \\text{Entropy}(\\text{Parent}) - \\text{Entropy}(\\text{Child}) $ \n",
      "\n",
      "$ \\text{Gini Impurity} = 1 - \\sum_{i=1}^{c} p_i^2 $ \n",
      "\n",
      "$ \\text{Entropy} = - \\sum_{i=1}^{c} p_i \\log_2 p_i $ \n",
      "\n",
      "$ \\text{Confusion Matrix} = \\begin{bmatrix} \\text{TP} & \\text{FP} \\\\ \\text{FN} & \\text{TN} \\end{bmatrix} $ \n",
      "\n",
      "$ \\text{ROC Curve} = \\text{True Positive Rate} \\text{ vs. } \\text{False Positive Rate} $ \n",
      "\n",
      "$ \\text{AUC-ROC} = \\text{Area Under the ROC Curve} $ \n",
      "\n",
      "$ \\text{Precision-Recall Curve} = \\text{Precision} \\text{ vs. } \\text{Recall} $ \n",
      "\n",
      "$ \\text{AUC-PR} = \\text{Area Under the Precision-Recall Curve} $ \n",
      "\n",
      "$ \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $ \n",
      "\n",
      "$ \\text{Mean Average Precision (MAP)} = \\frac{1}{n} \\sum_{i=1}^{n} \\text{Average Precision}_i $ \n",
      "\n",
      "$ \\text{Mean Reciprocal Rank (MRR)} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{\\text{Rank}_i} $ \n",
      "\n",
      "$ \\text{Normalized Discounted Cumulative Gain (NDCG)} = \\frac{\\text{DCG}}{\\text{IDCG}} $ \n",
      "\n",
      "$ \\text{Discounted Cumulative Gain (DCG)} = \\sum_{i=1}^{n} \\frac{2^{\\text{Relevance}_i} - 1}{\\log_2 (i + 1)} $ \n",
      "\n",
      "$ \\text{Ideal Discounted Cumulative Gain (IDCG)} = \\sum_{i=1}^{n} \\frac{2^{\\text{Relevance}_i} - 1}{\\log_2 (i + 1)} $ \n",
      "\n",
      "$ \\text{Relevance} = \\text{Relevance Score} $ \n",
      "\n",
      "$ \\text{Rank} = \\text{Ranking Position} $ \n",
      "\n",
      "$ \\text{IDCG} = \\text{Ideal Discounted Cumulative Gain} $ \n",
      "\n",
      "$ \\text{DCG} = \\text{Discounted Cumulative Gain} $ \n",
      "\n",
      "$ \\text{NDCG} = \\text{Normalized Discounted Cumulative Gain} $ \n",
      "\n",
      "$ \\text{MAP} = \\text{Mean Average Precision} $ \n",
      "\n",
      "$ \\text{MRR} = \\text{Mean Reciprocal Rank} $ \n",
      "\n",
      "$ \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $ \n",
      "\n",
      "$ \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}} $ \n",
      "\n",
      "$ \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}} $ \n",
      "\n",
      "$ \\text{Accuracy} = \\frac{\\text{True Positives} + \\text{True Negatives}}{\\text{Total Samples}} $ \n",
      "\n",
      "$ \\text{Mean Squared Error (MSE)} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $ \n",
      "\n",
      "$ \\text{Mean Absolute Error (MAE)} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| $ \n",
      "\n",
      "$ \\text{Root Mean Squared Error (RMSE)} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} $ \n",
      "\n",
      "$ \\text{Coefficient of Determination (R-Squared)} = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2} $ \n",
      "\n",
      "$ \\text{Information Gain} = \\text{Entropy}(\\text{Parent}) - \\text{Entropy}(\\text{Child}) $ \n",
      "\n",
      "$ \\text{Gini Impurity} = 1 - \\sum_{i=1}^{c} p_i^2 $ \n",
      "\n",
      "$ \\text{Entropy} = - \\sum_{i=1}^{c} p_i \\log_2 p_i $ \n",
      "\n",
      "$ \\text{Confusion Matrix} = \\begin{bmatrix} \\text{TP} & \\text{FP} \\\\ \\text{FN} & \\text{TN} \\end{bmatrix} $ \n",
      "\n",
      "$ \\text{ROC Curve} = \\text{True Positive Rate} \\text{ vs. } \\text{False Positive Rate} $ \n",
      "\n",
      "$ \\text{AUC-ROC} = \\text{Area Under the ROC Curve} $ \n",
      "\n",
      "$ \\text{Precision-Recall Curve} = \\text{Precision} \\text{ vs. } \\text{Recall} $ \n",
      "\n",
      "$ \\text{AUC-PR} = \\text{Area Under the Precision-Recall Curve} $ \n",
      "\n",
      "$ \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 74\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mProposalWithDSpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_proposal\n\u001b[1;32m      3\u001b[0m client_requirements \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m### **Client Requirements for AI-Powered Predictive Analytics for Healthcare**\u001b[39m\n\u001b[1;32m      5\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124m- Offer ongoing training for new staff members or system changes.\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 74\u001b[0m \u001b[43mgenerate_proposal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_requirements\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "from ProposalWithDSpy import generate_proposal\n",
    "\n",
    "client_requirements = \"\"\"\n",
    "### **Client Requirements for AI-Powered Predictive Analytics for Healthcare**\n",
    "\n",
    "**1. Project Overview:**\n",
    "- The client seeks to develop an AI-driven predictive analytics system for a healthcare network. \n",
    "- The system should predict patient outcomes, monitor chronic diseases, and optimize hospital resource management. \n",
    "- The system must integrate with the existing Electronic Health Record (EHR) system and provide actionable insights for medical practitioners.\n",
    "\n",
    "**2. Functional Requirements:**\n",
    "- The AI model should predict patient risks (such as the likelihood of readmission, disease progression, or complications).\n",
    "- The system should identify at-risk patients for conditions such as diabetes, heart disease, and other chronic illnesses.\n",
    "- Integrate predictive models for hospital resource utilization, including bed occupancy, staff availability, and equipment usage.\n",
    "- Provide real-time patient monitoring and alerts to healthcare providers.\n",
    "- The system must handle large datasets from various healthcare sources, including EHRs, lab results, and wearable devices.\n",
    "\n",
    "**3. Data and Model Specifications:**\n",
    "- Machine learning models should be trained using historical patient data (e.g., diagnosis, treatment plans, lab results).\n",
    "- The AI system should use classification models such as decision trees, logistic regression, random forests, and neural networks.\n",
    "- Natural Language Processing (NLP) algorithms should be used for processing unstructured text data from medical notes.\n",
    "- The client requires models to have explainable AI (XAI) features to help medical professionals understand how decisions are made.\n",
    "- The system should be capable of continuous learning to adapt to new data over time.\n",
    "\n",
    "**4. Integration and Infrastructure:**\n",
    "- The system should integrate with the existing EHR software through APIs.\n",
    "- Implement cloud-based infrastructure for real-time data processing and storage.\n",
    "- Ensure the system is scalable to handle increasing data loads from multiple healthcare centers.\n",
    "- Data security must be a priority, with compliance to HIPAA and other healthcare privacy standards.\n",
    "\n",
    "**5. User Interface:**\n",
    "- Provide a user-friendly dashboard for healthcare professionals to view predictions, trends, and insights.\n",
    "- The interface should allow users to interact with the model outputs, adjust parameters, and view patient reports.\n",
    "- Include visualization tools like graphs and heatmaps for easier interpretation of patient data and risk assessments.\n",
    "- Alerts and notifications should be integrated into the dashboard to inform practitioners of critical patient conditions.\n",
    "\n",
    "**6. Performance and Testing:**\n",
    "- The predictive models should achieve an accuracy rate of at least 85% for patient outcomes.\n",
    "- The system should have high precision and recall for detecting high-risk patients.\n",
    "- Perform extensive testing using real-world healthcare data to validate the model’s accuracy and reliability.\n",
    "- Conduct A/B testing with healthcare practitioners to ensure usability and relevance of insights.\n",
    "\n",
    "**7. Security and Compliance:**\n",
    "- Ensure end-to-end encryption of patient data and adherence to data privacy laws such as HIPAA.\n",
    "- The system must log all access to patient data for auditing purposes.\n",
    "- Implement role-based access controls to limit user permissions and data exposure.\n",
    "- Perform regular security audits to identify vulnerabilities and ensure ongoing compliance.\n",
    "\n",
    "**8. Deliverables:**\n",
    "- Fully functional AI model integrated with the existing healthcare infrastructure.\n",
    "- User-friendly dashboard for real-time monitoring and decision support.\n",
    "- Technical documentation detailing model development, API integration, and deployment instructions.\n",
    "- Data security measures and privacy compliance documentation.\n",
    "- Training sessions for healthcare staff on system usage.\n",
    "\n",
    "**9. Budget:**\n",
    "- The total project budget is capped at $1.2 million, inclusive of data collection, AI model development, system integration, and security features.\n",
    "- A detailed cost breakdown should be provided for each phase of the project, including infrastructure setup, model development, and ongoing maintenance.\n",
    "\n",
    "**10. Timeline:**\n",
    "- The client requires the project to be completed within 12 months.\n",
    "  - **Data Collection and Preparation:** 3 months\n",
    "  - **Model Development and Training:** 4 months\n",
    "  - **System Integration and API Development:** 2 months\n",
    "  - **Testing and Validation:** 2 months\n",
    "  - **Deployment and Staff Training:** 1 month\n",
    "\n",
    "**11. Post-Completion Support:**\n",
    "- The client requests a 12-month post-launch support period to address any technical issues or model updates.\n",
    "- Provide regular model performance reviews and updates based on new data.\n",
    "- Offer ongoing training for new staff members or system changes.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.6)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/saranathp/Fun-with-LLMs/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
